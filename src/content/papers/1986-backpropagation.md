---
title: "Learning Representations by Back-propagating Errors"
authors: "David E. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams"
date: "1986-10-09"
abstract: "We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector."
pdf_link: "/papers/1986-backpropagation.pdf"
cover: "../../assets/gallery/1986-backpropagation.png"
---

### Core Insight

Through the backpropagation algorithm, multi-layer neural networks could finally handle complex, non-linear realities. From this point on, deep learning transformed from a mere concept into an evolving force.
